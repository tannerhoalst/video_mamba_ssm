@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})


@article{depth_anything_v2,
  title={Depth Anything V2},
  author={Yang, Lihe and Kang, Bingyi and Huang, Zilong and Zhao, Zhen and Xu, Xiaogang and Feng, Jiashi and Zhao, Hengshuang},
  journal={arXiv:2406.09414},
  year={2024}
}

@inproceedings{depth_anything_v1,
  title={Depth Anything: Unleashing the Power of Large-Scale Unlabeled Data}, 
  author={Yang, Lihe and Kang, Bingyi and Huang, Zilong and Xu, Xiaogang and Feng, Jiashi and Zhao, Hengshuang},
  booktitle={CVPR},
  year={2024}
}

@ARTICLE {Ranftl2022,
    author  = "Ren\'{e} Ranftl and Katrin Lasinger and David Hafner and Konrad Schindler and Vladlen Koltun",
    title   = "Towards Robust Monocular Depth Estimation: Mixing Datasets for Zero-Shot Cross-Dataset Transfer",
    journal = "IEEE Transactions on Pattern Analysis and Machine Intelligence",
    year    = "2022",
    volume  = "44",
    number  = "3"
}


@article{hu2024depthcrafter,
  title={Depthcrafter: Generating consistent long depth sequences for open-world videos},
  author={Hu, Wenbo and Gao, Xiangjun and Li, Xiaoyu and Zhao, Sijie and Cun, Xiaodong and Zhang, Yong and Quan, Long and Shan, Ying},
  journal={arXiv preprint arXiv:2409.02095},
  year={2024}
}

@article{geiger2013vision,
  title={Vision meets robotics: The kitti dataset},
  author={Geiger, Andreas and Lenz, Philip and Stiller, Christoph and Urtasun, Raquel},
  journal={The International Journal of Robotics Research},
  volume={32},
  number={11},
  pages={1231--1237},
  year={2013},
  publisher={Sage Publications Sage UK: London, England}
}

@article{cabon2020virtual,
  title={Virtual kitti 2},
  author={Cabon, Yohann and Murray, Naila and Humenberger, Martin},
  journal={arXiv preprint arXiv:2001.10773},
  year={2020}
}

@inproceedings{dai2017scannet,
  title={Scannet: Richly-annotated 3d reconstructions of indoor scenes},
  author={Dai, Angela and Chang, Angel X and Savva, Manolis and Halber, Maciej and Funkhouser, Thomas and Nie{\ss}ner, Matthias},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={5828--5839},
  year={2017}
}


@article{birkl2023midas,
  title={Midas v3. 1--a model zoo for robust monocular relative depth estimation},
  author={Birkl, Reiner and Wofk, Diana and M{\"u}ller, Matthias},
  journal={arXiv preprint arXiv:2307.14460},
  year={2023}
}

@inproceedings{marigold,
  title={Repurposing diffusion-based image generators for monocular depth estimation},
  author={Ke, Bingxin and Obukhov, Anton and Huang, Shengyu and Metzger, Nando and Daudt, Rodrigo Caye and Schindler, Konrad},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9492--9502},
  year={2024}
}

@article{dong2022towards,
  title={Towards real-time monocular depth estimation for robotics: A survey},
  author={Dong, Xingshuai and Garratt, Matthew A and Anavatti, Sreenatha G and Abbass, Hussein A},
  journal={IEEE Transactions on Intelligent Transportation Systems},
  volume={23},
  number={10},
  pages={16940--16961},
  year={2022},
  publisher={IEEE}
}

@article{zhang2023controlvideo,
  title={Controlvideo: Training-free controllable text-to-video generation},
  author={Zhang, Yabo and Wei, Yuxiang and Jiang, Dongsheng and Zhang, Xiaopeng and Zuo, Wangmeng and Tian, Qi},
  journal={arXiv preprint arXiv:2305.13077},
  year={2023}
}

@article{peng2024controlnext,
  title={Controlnext: Powerful and efficient control for image and video generation},
  author={Peng, Bohao and Wang, Jian and Zhang, Yuechen and Li, Wenbo and Yang, Ming-Chang and Jia, Jiaya},
  journal={arXiv preprint arXiv:2408.06070},
  year={2024}
}


@article{holynski2018fast,
  title={Fast depth densification for occlusion-aware augmented reality},
  author={Holynski, Aleksander and Kopf, Johannes},
  journal={ACM Transactions on Graphics (ToG)},
  volume={37},
  number={6},
  pages={1--11},
  year={2018},
  publisher={ACM New York, NY, USA}
}

@inproceedings{kopf2021robust,
  title={Robust consistent video depth estimation},
  author={Kopf, Johannes and Rong, Xuejian and Huang, Jia-Bin},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1611--1621},
  year={2021}
}

@article{luo2020consistent,
  title={Consistent video depth estimation},
  author={Luo, Xuan and Huang, Jia-Bin and Szeliski, Richard and Matzen, Kevin and Kopf, Johannes},
  journal={ACM Transactions on Graphics (ToG)},
  volume={39},
  number={4},
  pages={71--1},
  year={2020},
  publisher={ACM New York, NY, USA}
}

@article{zhang2021consistent,
  title={Consistent depth of moving objects in video},
  author={Zhang, Zhoutong and Cole, Forrester and Tucker, Richard and Freeman, William T and Dekel, Tali},
  journal={ACM Transactions on Graphics (ToG)},
  volume={40},
  number={4},
  pages={1--12},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@inproceedings{wang2023neural,
  title={Neural video depth stabilizer},
  author={Wang, Yiran and Shi, Min and Li, Jiaqi and Huang, Zihao and Cao, Zhiguo and Zhang, Jianming and Xian, Ke and Lin, Guosheng},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={9466--9476},
  year={2023}
}

@misc{wang2021irslargenaturalisticindoor,
      title={IRS: A Large Naturalistic Indoor Robotics Stereo Dataset to Train Deep Models for Disparity and Surface Normal Estimation}, 
      author={Qiang Wang and Shizhen Zheng and Qingsong Yan and Fei Deng and Kaiyong Zhao and Xiaowen Chu},
      year={2021},
      eprint={1912.09678},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1912.09678}, 
}

@InProceedings{palazzolo2019iros,
author = {E. Palazzolo and J. Behley and P. Lottes and P. Gigu\`ere and C. Stachniss},
title = {{ReFusion: 3D Reconstruction in Dynamic Environments for RGB-D Cameras Exploiting Residuals}},
booktitle = iros,
year = {2019},
url = {https://www.ipb.uni-bonn.de/pdfs/palazzolo2019iros.pdf},
codeurl = {https://github.com/PRBonn/refusion},
videourl = {https://youtu.be/1P9ZfIS5-p4},
}

@inproceedings{Silberman:ECCV12,
  author    = {Nathan Silberman, Derek Hoiem, Pushmeet Kohli and Rob Fergus},
  title     = {Indoor Segmentation and Support Inference from RGBD Images},
  booktitle = {ECCV},
  year      = {2012}
}

@inproceedings{Schops_Schonberger_Galliani_Sattler_Schindler_Pollefeys_Geiger_2017,   title={A Multi-view Stereo Benchmark with High-Resolution Images and Multi-camera Videos},  url={http://dx.doi.org/10.1109/cvpr.2017.272},  DOI={10.1109/cvpr.2017.272},  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},  author={Schops, Thomas and Schonberger, Johannes L. and Galliani, Silvano and Sattler, Torsten and Schindler, Konrad and Pollefeys, Marc and Geiger, Andreas},  year={2017},  month={Jul},  language={en-US}  }

@article{Igor_Nicholas_Zhang_Luo_Wang_Dai_Daniele_Mostajabi_Basart_Walter_et_al_2019,   title={DIODE: A Dense Indoor and Outdoor DEpth Dataset.},  journal={arXiv: Computer Vision and Pattern Recognition,arXiv: Computer Vision and Pattern Recognition},  author={Igor, Vasiljevic and Nicholas, Kolkin and Zhang, Shanyi and Luo, Ruotian and Wang, Haochen and Dai, FalconZ. and Daniele, AndreaF. and Mostajabi, Mohammadreza and Basart, Steven and Walter, MatthewR. and Shakhnarovich, Gregory},  year={2019},  month={Aug},  language={en-US}  }

 @inbook{Butler_Wulff_Stanley_Black_2012,  
 title={A Naturalistic Open Source Movie for Optical Flow Evaluation}, 
 url={http://dx.doi.org/10.1007/978-3-642-33783-3_44}, 
 DOI={10.1007/978-3-642-33783-3_44}, 
 booktitle={Computer Vision – ECCV 2012,Lecture Notes in Computer Science}, 
 author={Butler, Daniel J. and Wulff, Jonas and Stanley, Garrett B. and Black, Michael J.}, 
 year={2012}, 
 month={Jan}, 
 pages={611–625}, 
 language={en-US} 
 }

@inproceedings{xu2022gmflow,
  title={Gmflow: Learning optical flow via global matching},
  author={Xu, Haofei and Zhang, Jing and Cai, Jianfei and Rezatofighi, Hamid and Tao, Dacheng},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={8121--8130},
  year={2022}
}

@inproceedings{schonberger2016structure,
  title={Structure-from-motion revisited},
  author={Schonberger, Johannes L and Frahm, Jan-Michael},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4104--4113},
  year={2016}
}

@article{depthanyvideo,
  title={Depth Any Video with Scalable Synthetic Data},
  author={Yang, Honghui and Huang, Di and Yin, Wei and Shen, Chunhua and Liu, Haifeng and He, Xiaofei and Lin, Binbin and Ouyang, Wanli and He, Tong},
  journal={arXiv preprint arXiv:2410.10815},
  year={2024}
}


@article{chronodepth,
  title={Learning Temporally Consistent Video Depth from Video Diffusion Priors},
  author={Shao, Jiahao and Yang, Yuanbo and Zhou, Hongyu and Zhang, Youmin and Shen, Yujun and Poggi, Matteo and Liao, Yiyi},
  journal={arXiv preprint arXiv:2406.01493},
  year={2024}
}

@article{blattmann2023stable,
  title={Stable video diffusion: Scaling latent video diffusion models to large datasets},
  author={Blattmann, Andreas and Dockhorn, Tim and Kulal, Sumith and Mendelevitch, Daniel and Kilian, Maciej and Lorenz, Dominik and Levi, Yam and English, Zion and Voleti, Vikram and Letts, Adam and others},
  journal={arXiv preprint arXiv:2311.15127},
  year={2023}
}

@inproceedings{ranftl2021vision,
  title={Vision transformers for dense prediction},
  author={Ranftl, Ren{\'e} and Bochkovskiy, Alexey and Koltun, Vladlen},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={12179--12188},
  year={2021}
}

@inproceedings{Perazzi2016davis,
  author = {F. Perazzi and J. Pont-Tuset and B. McWilliams and L. {Van Gool} and M. Gross and A. Sorkine-Hornung},
  title = {A Benchmark Dataset and Evaluation Methodology for Video Object Segmentation},
  booktitle = {Computer Vision and Pattern Recognition},
  year = {2016}
}

@inproceedings{cortes2018advio,
  title={ADVIO: An authentic dataset for visual-inertial odometry},
  author={Cort{\'e}s, Santiago and Solin, Arno and Rahtu, Esa and Kannala, Juho},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={419--434},
  year={2018}
}

@inproceedings{bhat2021adabins,
  title={Adabins: Depth estimation using adaptive bins},
  author={Bhat, Shariq Farooq and Alhashim, Ibraheem and Wonka, Peter},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={4009--4018},
  year={2021}
}

@article{eigen2014depth,
  title={Depth map prediction from a single image using a multi-scale deep network},
  author={Eigen, David and Puhrsch, Christian and Fergus, Rob},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@inproceedings{fu2018dorn,
  title={Deep ordinal regression network for monocular depth estimation},
  author={Fu, Huan and Gong, Mingming and Wang, Chaohui and Batmanghelich, Kayhan and Tao, Dacheng},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2002--2011},
  year={2018}
}

@inproceedings{yuan2022crf,
  title={Neural window fully-connected crfs for monocular depth estimation},
  author={Yuan, Weihao and Gu, Xiaodong and Dai, Zuozhuo and Zhu, Siyu and Tan, Ping},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={3916--3925},
  year={2022}
}

@article{bhat2023zoedepth,
  title={Zoedepth: Zero-shot transfer by combining relative and metric depth},
  author={Bhat, Shariq Farooq and Birkl, Reiner and Wofk, Diana and Wonka, Peter and M{\"u}ller, Matthias},
  journal={arXiv preprint arXiv:2302.12288},
  year={2023}
}

@inproceedings{yin2023metric3d,
  title={Metric3d: Towards zero-shot metric 3d prediction from a single image},
  author={Yin, Wei and Zhang, Chi and Chen, Hao and Cai, Zhipeng and Yu, Gang and Wang, Kaixuan and Chen, Xiaozhi and Shen, Chunhua},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={9043--9053},
  year={2023}
}

@inproceedings{piccinelli2024unidepth,
  title={UniDepth: Universal Monocular Metric Depth Estimation},
  author={Piccinelli, Luigi and Yang, Yung-Hsu and Sakaridis, Christos and Segu, Mattia and Li, Siyuan and Van Gool, Luc and Yu, Fisher},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10106--10116},
  year={2024}
}

@article{oquab2023dinov2,
  title={Dinov2: Learning robust visual features without supervision},
  author={Oquab, Maxime and Darcet, Timoth{\'e}e and Moutakanni, Th{\'e}o and Vo, Huy and Szafraniec, Marc and Khalidov, Vasil and Fernandez, Pierre and Haziza, Daniel and Massa, Francisco and El-Nouby, Alaaeldin and others},
  journal={arXiv preprint arXiv:2304.07193},
  year={2023}
}

@inproceedings{yasarla2023mamo,
  title={Mamo: Leveraging memory and attention for monocular video depth estimation},
  author={Yasarla, Rajeev and Cai, Hong and Jeong, Jisoo and Shi, Yunxiao and Garrepalli, Risheek and Porikli, Fatih},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={8754--8764},
  year={2023}
}

@inproceedings{teed2020raft,
  title={Raft: Recurrent all-pairs field transforms for optical flow},
  author={Teed, Zachary and Deng, Jia},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part II 16},
  pages={402--419},
  year={2020},
  organization={Springer}
}

@inproceedings{sayed2022simplerecon,
  title={Simplerecon: 3d reconstruction without 3d convolutions},
  author={Sayed, Mohamed and Gibson, John and Watson, Jamie and Prisacariu, Victor and Firman, Michael and Godard, Cl{\'e}ment},
  booktitle={European Conference on Computer Vision},
  pages={1--19},
  year={2022},
  organization={Springer}
}

@inproceedings{wang2020tartanair,
  title={Tartanair: A dataset to push the limits of visual slam},
  author={Wang, Wenshan and Zhu, Delong and Wang, Xiangwei and Hu, Yaoyu and Qiu, Yuheng and Wang, Chen and Hu, Yafei and Kapoor, Ashish and Scherer, Sebastian},
  booktitle={2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={4909--4916},
  year={2020},
  organization={IEEE}
}

@inproceedings{zheng2023pointodyssey,
  title={Pointodyssey: A large-scale synthetic dataset for long-term point tracking},
  author={Zheng, Yang and Harley, Adam W and Shen, Bokui and Wetzstein, Gordon and Guibas, Leonidas J},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={19855--19865},
  year={2023}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, A},
  journal={Advances in Neural Information Processing Systems},
  year={2017}
}

@article{su2024roformer,
  title={Roformer: Enhanced transformer with rotary position embedding},
  author={Su, Jianlin and Ahmed, Murtadha and Lu, Yu and Pan, Shengfeng and Bo, Wen and Liu, Yunfeng},
  journal={Neurocomputing},
  volume={568},
  pages={127063},
  year={2024},
  publisher={Elsevier}
}

@inproceedings{10.1145/3591106.3592264,
author = {Li, Pengzhi and Ding, Yikang and Li, Linge and Guan, Jingwei and Li, Zhiheng},
title = {Towards Practical Consistent Video Depth Estimation},
year = {2023},
isbn = {9798400701788},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3591106.3592264},
doi = {10.1145/3591106.3592264},
booktitle = {Proceedings of the 2023 ACM International Conference on Multimedia Retrieval},
pages = {388–397},
numpages = {10},
keywords = {Depth estimation, Temporal consistency, Video},
location = {Thessaloniki, Greece},
series = {ICMR '23}
}

@inproceedings{Wang_2022, series={MM ’22},
   title={Less is More: Consistent Video Depth Estimation with Masked Frames Modeling},
   url={http://dx.doi.org/10.1145/3503161.3547978},
   DOI={10.1145/3503161.3547978},
   booktitle={Proceedings of the 30th ACM International Conference on Multimedia},
   publisher={ACM},
   author={Wang, Yiran and Pan, Zhiyu and Li, Xingyi and Cao, Zhiguo and Xian, Ke and Zhang, Jianming},
   year={2022},
   month=oct, pages={6347–6358},
   collection={MM ’22} }

@article{liu2024sora,
  title={Sora: A review on background, technology, limitations, and opportunities of large vision models},
  author={Liu, Yixin and Zhang, Kai and Li, Yuan and Yan, Zhiling and Gao, Chujie and Chen, Ruoxi and Yuan, Zhengqing and Huang, Yue and Sun, Hanchi and Gao, Jianfeng and others},
  journal={arXiv preprint arXiv:2402.17177},
  year={2024}
}

@article{loshchilov2017decoupled,
  title={Decoupled weight decay regularization},
  author={Loshchilov, I},
  journal={arXiv preprint arXiv:1711.05101},
  year={2017}
}

@article{huang2024wildavatar,
    title={WildAvatar: Web-scale In-the-wild Video Dataset for 3D Avatar Creation},
    author={Huang, Zihao and Hu, ShouKang and Wang, Guangcong and Liu, Tianqi and Zang, Yuhang and Cao, Zhiguo and Li, Wei and Liu, Ziwei},
    journal={arXiv preprint arXiv:2407.02165},
    year={2024}
    }

@article{jing2024match-stereo-videos,
  title={Match-Stereo-Videos: Bidirectional Alignment for Consistent Dynamic Stereo Matching},
  author={Junpeng Jing and Ye Mao and Krystian Mikolajczyk},
  year={2024}
}

@misc{wang2024moge,
    title={MoGe: Unlocking Accurate Monocular Geometry Estimation for Open-Domain Images with Optimal Training Supervision},
    author={Wang, Ruicheng and Xu, Sicheng and Dai, Cassie and Xiang, Jianfeng and Deng, Yu and Tong, Xin and Yang, Jiaolong},
    year={2024},
    eprint={2410.19115},
    archivePrefix={arXiv},
    primaryClass={cs.CV},
    url={https://arxiv.org/abs/2410.19115}, 
}