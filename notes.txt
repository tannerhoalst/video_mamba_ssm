codex --model=gpt-5.1-codex-max \
  --dangerously-bypass-approvals-and-sandbox \
  --enable web_search_request \
  -c model_reasoning_effort="high"



sudo apt-get update
sudo apt-get install -y libjpeg-dev zlib1g-dev libopenjp2-7-dev libtiff-dev libwebp-dev liblcms2-dev
sudo apt-get install -y build-essential cmake ninja-build

python3 -m venv .venv
source .venv/bin/activate

CC="cc -mavx2" uv pip install \
  --index-url https://pypi.org/simple \
  --extra-index-url https://download.pytorch.org/whl/cu130 \
  --index-strategy unsafe-best-match \
  -r UniDepth/requirements.txt --upgrade --force-reinstall

uv pip install -v --no-build-isolation -U git+https://github.com/facebookresearch/xformers.git@main#egg=xformers
uv pip install -e UniDepth

cd UniDepth/unidepth/ops/knn
TORCH_CUDA_ARCH_LIST="8.0 8.6 8.9 9.0+PTX" uv pip install -v --no-build-isolation .

cd ../extract_patches
TORCH_CUDA_ARCH_LIST="8.0 8.6 8.9 9.0+PTX" uv pip install -v --no-build-isolation .
cd ../../../..

python -m unidepth.models.unidepthv2.inference \
  --image /home/thoalst/Pictures/Screenshots/ufc.png \
  --model-id lpiccinelli/unidepth-v2-vitb14 \
  --save-depth /mnt/vrdata/depth_maps/unidepth/ufc.npy


python visualize_depth.py /mnt/vrdata/depth_maps/unidepth/ufc.npy


python benchmark_unidepth_inprocess.py --image /home/thoalst/Pictures/Screenshots/ufc.png --runs 60 --warmup 3 --model-id lpiccinelli/unidepth-v2-vitb14

  - defaults: 5 warm-up runs, 60 timed runs, image /home/thoalst/Pictures/Screenshots/savannah.png, model lpiccinelli/unidepth-v2-vits14, device auto (CUDA if available).
Common options:
  - --runs 100 to change the timed loop count.
  - --warmup 2 to adjust warm-ups.
  - --image /path/to/img.png to test another image.
  - --device cpu to force CPU.
  - --save-depth /mnt/vrdata/depth_maps/unidepth/savannah_loop.npy to save the depth from the last timed run only (avoids I/O in the loop).
  - --verbose to print per-run timings.